---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

![Recursive optimization scheme](/images/generationtrees.png){: .align-right width="400px"}

 I am interested in designing efficient and exact algorithms for solving intractable combinatorial optimization problems, many of which are NP-complete/NP-hard problems. 

My current studies employ a formal formalism, known as **transformational programming**,  to design reliable and efficient algorithms. Combined with the studies in **the algebra of programming**, **combinatorial/computational geometry**, and **combinatorial generation**, I established a generic framework for designing combinatorial optimization algorithms in a more general optimization setting, we call this framework **recursive optimization scheme**.

Currently, I focus on applying our generic framework in machine learning research. For instance, we previously designed a polynomial-time algorithm for solving the 0-1 loss linear classification problem exactly, this classic problem, dating back almost a century to Ronald Fisher’s pioneering work in 1936, has persisted as a challenge in the field. A breakthrough, nearly 30 years after the support vector machine was invented by Vapnik et al.

More recently, we have successfully designed many sequential and parallelized algorithms for solving many classical intricate combinatorial machine learning problems, including the 0-1 loss hypersurface classification problem, the K-medoids problem, and the 2-means problem. Numerous potential applications of our generic framework can be invested further, we believe this formalism presents a promising avenue for designing reliable and tractable machine learning algorithms that are sound and concise.

# Experience

## Education

- Dec. 2021- present:  I am a third-year PhD student from the [Department of Computer Science](https://www.birmingham.ac.uk/schools/computer-science/index.aspx), [University of Birmingham](https://www.birmingham.ac.uk/index.aspx), supervised by Dr. [Max. Little](http://www.maxlittle.net/home/index.php). 
- Sept. 2017- June 2021: *Bachelor of Science* at [Zhejiang Normal University](https://www.zjnu.edu.cn/main.htm).  Where I majored in Mechanical Design Manufacturing and Automation.

## Research

- [An efficient, provably exact, practical algorithm for the 0-1 loss linear classification problem](https://arxiv.org/pdf/2306.12344.pdf) **Xi He**, Waheed Ul Rahman, Max A. Little (Under review in the Journal of Machine Learning Research)
- [Dynamic programming by polymorphic algebraic shortcut fusion](https://arxiv.org/pdf/2107.01752.pdf) Max A. Little, **Xi He**, Ugur Kayas (Under review in the Formal Aspects of Computing)

These three papers are talking about the same story, that is, a recursive optimization algorithm (or dynamic programming) can be constructed, accelerated and reconstructed through the identification of monotonicity (distributivity in the function case).

## Software

You can find the Python implementations of my algorithms from my [Git repositories](https://github.com/XiHegrt).

## Activities

- 2-6 April, 2023 Attending [Midlands Graduate School 2023 (bham.ac.uk)](https://www.cs.bham.ac.uk/~mhe/events/MGS23/), Birmingham, UK 
- 13 June, 2023 Attending [Advances in Data Science and AI Conference 2023 (manchester.ac.uk)](https://events.manchester.ac.uk/event/event:k14l-leplq84p-od61dv/idsai-advances-in-data-science-and-ai-conference-2023), Manchester

## Profile

My name is Xi He,  which is the Chinese transcription of "何希",  "Xi" pronounce as "She", it means "hope" in Chinese.

I enjoy lifting weights, basketball and hiking in my free time. I also write some [blogs](https://xihegrt.github.io/year-archive/) sometimes.
